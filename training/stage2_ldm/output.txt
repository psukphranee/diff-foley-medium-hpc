/Users/920753844/Diff-Foley/training/stage2_ldm/adm/modules/stage2_decode/decode_wrapper.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(path, map_location="cpu")
Home directory: /Users/920753844
Import sucessful: get_model_config() is callable.
Listing Available Models: -------------------------------------
audio_contrastive
audio_contrastive_dim1024
audio_contrastive_pretrained
audio_contrastive_spec_aug
coca_base
coca_roberta-ViT-B-32
coca_ViT-B-32
coca_ViT-L-14
convnext_base
convnext_base_w
convnext_base_w_320
convnext_large
convnext_large_d
convnext_small
convnext_tiny
convnext_xlarge
convnext_xxlarge
convnext_xxlarge_320
mt5-base-ViT-B-32
mt5-xl-ViT-H-14
RN50
RN50-quickgelu
RN50x4
RN50x16
RN50x64
RN101
RN101-quickgelu
roberta-ViT-B-32
swin_base_patch4_window7_224
ViT-B-16
ViT-B-16-plus
ViT-B-16-plus-240
ViT-B-32
ViT-B-32-plus-256
ViT-B-32-quickgelu
ViT-bigG-14
ViT-e-14
ViT-g-14
ViT-H-14
ViT-H-16
ViT-L-14
ViT-L-14-280
ViT-L-14-336
ViT-L-16
ViT-L-16-320
ViT-M-16
ViT-M-16-alt
ViT-M-32
ViT-M-32-alt
ViT-S-16
ViT-S-16-alt
ViT-S-32
ViT-S-32-alt
vit_medium_patch16_gap_256
vit_relpos_medium_patch16_cls_224
xlm-roberta-base-ViT-B-32
xlm-roberta-large-ViT-H-14
---------------------------------------------------------------
Assert that CLIP_Video_Spec_v2 is importable. <class 'adm.modules.stage2_decode.clip_video_spec.CLIP_Video_Spec_v2'>
Assert that CLIP_Video_Spec is importable. <class 'adm.modules.stage2_decode.clip_video_spec.CLIP_Video_Spec'>
Loading configuration of audio_contrastive_pretrained: ----
{
    "audio_pretrained": true,
    "embed_dim": 512,
    "params": {
        "embed_dim": 512,
        "spec_encode": "cnn14_pool",
        "video_encode": "Slowonly"
    },
    "target": "adm.modules.stage2_decode.clip_video_spec.CLIP_Video_Spec",
    "text_cfg": {
        "context_length": 77,
        "heads": 8,
        "layers": 12,
        "vocab_size": 49408,
        "width": 512
    },
    "video_pretrained": true,
    "vision_cfg": {
        "image_size": 224,
        "layers": [
            3,
            4,
            6,
            3
        ],
        "patch_size": null,
        "width": 64
    }
}
---------------------------------------------------------------
Panya: Loaded model from checkpoint in decode_wrapper.py
Restored from /Users/920753844/Diff-Foley/training/open_cavp_main/logs/2024_10_21-14_32_19-lr_8e-4_warmup200_wds_vgg+audioset_cnn14_pretrained_clip_num3_shift_lb8_intra_loss_w1/checkpoints/epoch_latest.pt with 0 missing and 81 unexpected keys
Unexpected Keys: ['spec_encoder.bn.weight', 'spec_encoder.bn.bias', 'spec_encoder.bn.running_mean', 'spec_encoder.bn.running_var', 'spec_encoder.bn.num_batches_tracked', 'spec_encoder.conv_block1.conv1.weight', 'spec_encoder.conv_block1.conv2.weight', 'spec_encoder.conv_block1.bn1.weight', 'spec_encoder.conv_block1.bn1.bias', 'spec_encoder.conv_block1.bn1.running_mean', 'spec_encoder.conv_block1.bn1.running_var', 'spec_encoder.conv_block1.bn1.num_batches_tracked', 'spec_encoder.conv_block1.bn2.weight', 'spec_encoder.conv_block1.bn2.bias', 'spec_encoder.conv_block1.bn2.running_mean', 'spec_encoder.conv_block1.bn2.running_var', 'spec_encoder.conv_block1.bn2.num_batches_tracked', 'spec_encoder.conv_block2.conv1.weight', 'spec_encoder.conv_block2.conv2.weight', 'spec_encoder.conv_block2.bn1.weight', 'spec_encoder.conv_block2.bn1.bias', 'spec_encoder.conv_block2.bn1.running_mean', 'spec_encoder.conv_block2.bn1.running_var', 'spec_encoder.conv_block2.bn1.num_batches_tracked', 'spec_encoder.conv_block2.bn2.weight', 'spec_encoder.conv_block2.bn2.bias', 'spec_encoder.conv_block2.bn2.running_mean', 'spec_encoder.conv_block2.bn2.running_var', 'spec_encoder.conv_block2.bn2.num_batches_tracked', 'spec_encoder.conv_block3.conv1.weight', 'spec_encoder.conv_block3.conv2.weight', 'spec_encoder.conv_block3.bn1.weight', 'spec_encoder.conv_block3.bn1.bias', 'spec_encoder.conv_block3.bn1.running_mean', 'spec_encoder.conv_block3.bn1.running_var', 'spec_encoder.conv_block3.bn1.num_batches_tracked', 'spec_encoder.conv_block3.bn2.weight', 'spec_encoder.conv_block3.bn2.bias', 'spec_encoder.conv_block3.bn2.running_mean', 'spec_encoder.conv_block3.bn2.running_var', 'spec_encoder.conv_block3.bn2.num_batches_tracked', 'spec_encoder.conv_block4.conv1.weight', 'spec_encoder.conv_block4.conv2.weight', 'spec_encoder.conv_block4.bn1.weight', 'spec_encoder.conv_block4.bn1.bias', 'spec_encoder.conv_block4.bn1.running_mean', 'spec_encoder.conv_block4.bn1.running_var', 'spec_encoder.conv_block4.bn1.num_batches_tracked', 'spec_encoder.conv_block4.bn2.weight', 'spec_encoder.conv_block4.bn2.bias', 'spec_encoder.conv_block4.bn2.running_mean', 'spec_encoder.conv_block4.bn2.running_var', 'spec_encoder.conv_block4.bn2.num_batches_tracked', 'spec_encoder.conv_block5.conv1.weight', 'spec_encoder.conv_block5.conv2.weight', 'spec_encoder.conv_block5.bn1.weight', 'spec_encoder.conv_block5.bn1.bias', 'spec_encoder.conv_block5.bn1.running_mean', 'spec_encoder.conv_block5.bn1.running_var', 'spec_encoder.conv_block5.bn1.num_batches_tracked', 'spec_encoder.conv_block5.bn2.weight', 'spec_encoder.conv_block5.bn2.bias', 'spec_encoder.conv_block5.bn2.running_mean', 'spec_encoder.conv_block5.bn2.running_var', 'spec_encoder.conv_block5.bn2.num_batches_tracked', 'spec_encoder.conv_block6.conv1.weight', 'spec_encoder.conv_block6.conv2.weight', 'spec_encoder.conv_block6.bn1.weight', 'spec_encoder.conv_block6.bn1.bias', 'spec_encoder.conv_block6.bn1.running_mean', 'spec_encoder.conv_block6.bn1.running_var', 'spec_encoder.conv_block6.bn1.num_batches_tracked', 'spec_encoder.conv_block6.bn2.weight', 'spec_encoder.conv_block6.bn2.bias', 'spec_encoder.conv_block6.bn2.running_mean', 'spec_encoder.conv_block6.bn2.running_var', 'spec_encoder.conv_block6.bn2.num_batches_tracked', 'spec_encoder.fc1.weight', 'spec_encoder.fc1.bias', 'spec_encoder.final_project.weight', 'spec_encoder.final_project.bias']
