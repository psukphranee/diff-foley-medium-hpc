{"cells":[{"cell_type":"markdown","metadata":{"id":"1wN9ns2HWZQ7"},"source":["## Diff-Foley: Inference Pipeline."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ack5cdtOWZQ_","executionInfo":{"status":"error","timestamp":1738729787183,"user_tz":480,"elapsed":120,"user":{"displayName":"P Suk","userId":"09302626257048144669"}},"outputId":"144781bf-93da-4fea-e05f-34676df09f6d","colab":{"base_uri":"https://localhost:8080/","height":385}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'omegaconf'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-57c0ea6ae6dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'omegaconf'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from omegaconf import OmegaConf\n","import os\n","import torch\n","import numpy as np\n","import librosa\n","import soundfile as sf\n","from tqdm import tqdm\n","\n","import sys\n","sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1]))\n","from diff_foley.util import instantiate_from_config"]},{"cell_type":"markdown","metadata":{"id":"_eI1B7NSWZRB"},"source":["### 1. Loading Stage1 CAVP Model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AO3y1NWdWZRC","outputId":"0f8a384f-79e7-4b24-9d5a-874a95c234dc"},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["import os\n","from demo_util import Extract_CAVP_Features\n","\n","# Set Device:\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda\")\n","# Default Setting:\n","\n","fps = 4                                                     #  CAVP default FPS=4, Don't change it.\n","batch_size = 40   # Don't change it.\n","cavp_config_path = \"./config/Stage1_CAVP.yaml\"              #  CAVP Config\n","cavp_ckpt_path = \"./diff_foley_ckpt/cavp_epoch66.ckpt\"      #  CAVP Ckpt\n","\n","\n","# Initalize CAVP Model:\n","extract_cavp = Extract_CAVP_Features(fps=fps, batch_size=batch_size, device=device, config_path=cavp_config_path, ckpt_path=cavp_ckpt_path)"]},{"cell_type":"markdown","metadata":{"id":"IWGOCigZWZRD"},"source":["### 2. Loading Stage2 LDM Model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NlozqHGWZRE"},"outputs":[],"source":["def load_model_from_config(config, ckpt, verbose=False):\n","    print(f\"Loading model from {ckpt}\")\n","    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n","    if \"global_step\" in pl_sd:\n","        print(f\"Global Step: {pl_sd['global_step']}\")\n","    sd = pl_sd[\"state_dict\"]\n","    model = instantiate_from_config(config.model)\n","    m, u = model.load_state_dict(sd, strict=False)\n","    if len(m) > 0 and verbose:\n","        print(\"missing keys:\")\n","        print(m)\n","    if len(u) > 0 and verbose:\n","        print(\"unexpected keys:\")\n","        print(u)\n","    model.cuda()\n","    model.eval()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwU_YeDJWZRE","outputId":"82427c0d-f6a4-421d-9e08-5204c4c77aa9"},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["# LDM Config:\n","ldm_config_path = \"./config/Stage2_LDM.yaml\"\n","ldm_ckpt_path = \"./diff_foley_ckpt/ldm_epoch240.ckpt\"\n","config = OmegaConf.load(ldm_config_path)\n","\n","# Loading LDM:\n","latent_diffusion_model = load_model_from_config(config, ldm_ckpt_path)"]},{"cell_type":"markdown","metadata":{"id":"6GbRc6-4WZRF"},"source":["### 3. Data Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYDUGoLMWZRG","outputId":"f201c8a8-b19e-4e18-92e0-236a07a02fb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["video_path ./demo_videos/car.mp4\n","truncate second:  8.2\n"]},{"name":"stderr","output_type":"stream","text":["Processing Frames: 34 Total: 33.0: : 0it [00:00, ?it/s]\n"]}],"source":["\n","# Sample1:\n","video_path = \"./demo_videos/gun.mp4\"\n","save_path = \"./generate_samples/gun\"\n","tmp_path = \"./generate_samples/temp_folder\"\n","\n","## Sample2:\n","# video_path = \"./demo_videos/drum.mp4\"\n","# save_path = \"./generate_samples/drum\"\n","# tmp_path = \"./generate_samples/temp_folder\"\n","\n","## Sample3:\n","# video_path = \"./demo_videos/car.mp4\"\n","# save_path = \"./generate_samples/car\"\n","# tmp_path = \"./generate_samples/temp_folder\"\n","\n","\n","start_second = 0              # Video start second\n","truncate_second = 8.2         # Video end = start_second + truncate_second\n","\n","# Extract Video CAVP Features & New Video Path:\n","cavp_feats, new_video_path = extract_cavp(video_path, start_second, truncate_second, tmp_path=tmp_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oblz7sGxWZRH"},"outputs":[],"source":["def seed_everything(seed):\n","    import random, os\n","    import numpy as np\n","    import torch\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","seed_everything(21)"]},{"cell_type":"markdown","metadata":{"id":"FHH_SHcpWZRH"},"source":["### 4. Diff-Foley Generation:"]},{"cell_type":"markdown","metadata":{"id":"WVtx0-vAWZRH"},"source":["#### 4.(a) Double Guidance Load:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBAiXerqWZRH","outputId":"0615e574-2c79-43e4-99f9-f00aa34400a5"},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["# Whether use Double Guidance:\n","use_double_guidance = True\n","\n","if use_double_guidance:\n","    classifier_config_path = \"./config/Double_Guidance_Classifier.yaml\"\n","    classifier_ckpt_path = \"./diff_foley_ckpt/double_guidance_classifier.ckpt\"\n","    classifier_config = OmegaConf.load(classifier_config_path)\n","    classifier = load_model_from_config(classifier_config, classifier_ckpt_path)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TX06rcBOWZRI","outputId":"6ea4c098-290b-4b21-84fb-47b1b0ad8edf"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4, 33, 512])\n"]},{"name":"stderr","output_type":"stream","text":["Window::   0%|          | 0/1 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Using Double Guidance: True\n"]},{"name":"stderr","output_type":"stream","text":["current samples:: 100%|██████████| 4/4 [00:24<00:00,  6.10s/it]\n","Window:: 100%|██████████| 1/1 [00:29<00:00, 29.98s/it]\n"]}],"source":["from demo_util import inverse_op\n","\n","sample_num = 4\n","\n","# Inference Param:\n","cfg_scale = 4.5      # Classifier-Free Guidance Scale\n","cg_scale = 50        # Classifier Guidance Scale\n","\n","\n","steps = 25                # Inference Steps\n","\n","sampler = \"DPM_Solver\"    # DPM-Solver Sampler\n","# sampler = \"DDIM\"        # DDIM Sampler\n","# sampler = \"PLMS\"        # PLMS Sampler\n","\n","\n","save_path = save_path + \"_CFG{}_CG{}_{}_{}_useDG_{}\".format(cfg_scale, cg_scale, sampler, steps, use_double_guidance)\n","os.makedirs(save_path, exist_ok=True)\n","\n","# Video CAVP Features:\n","video_feat = torch.from_numpy(cavp_feats).unsqueeze(0).repeat(sample_num, 1, 1).to(device)\n","print(video_feat.shape)\n","\n","\n","# Truncate the Video Cond:\n","feat_len = video_feat.shape[1]\n","truncate_len = 32\n","window_num = feat_len // truncate_len\n","\n","\n","audio_list = []     # [sample_list1, sample_list2, sample_list3 ....]\n","for i in tqdm(range(window_num), desc=\"Window:\"):\n","    start, end = i * truncate_len, (i+1) * truncate_len\n","\n","    # 1). Get Video Condition Embed:\n","    embed_cond_feat = latent_diffusion_model.get_learned_conditioning(video_feat[:, start:end])\n","\n","    # 2). CFG unconditional Embedding:\n","    uncond_cond = torch.zeros(embed_cond_feat.shape).to(device)\n","\n","    # 3). Diffusion Sampling:\n","    print(\"Using Double Guidance: {}\".format(use_double_guidance))\n","    if use_double_guidance:\n","        audio_samples, _ = latent_diffusion_model.sample_log_with_classifier_diff_sampler(embed_cond_feat, origin_cond=video_feat, batch_size=video_feat.shape[0], sampler_name=sampler, ddim_steps=steps, unconditional_guidance_scale=cfg_scale,unconditional_conditioning=uncond_cond,classifier=classifier, classifier_guide_scale=cg_scale)  # Double Guidance\n","    else:\n","        audio_samples, _ = latent_diffusion_model.sample_log_diff_sampler(embed_cond_feat, batch_size=sample_num, sampler_name=sampler, ddim_steps=steps, unconditional_guidance_scale=cfg_scale,unconditional_conditioning=uncond_cond)           #  Classifier-Free Guidance\n","\n","    # 4). Decode Latent:\n","    audio_samples = latent_diffusion_model.decode_first_stage(audio_samples)\n","    audio_samples = audio_samples[:, 0, :, :].detach().cpu().numpy()\n","\n","    # 5). Spectrogram -> Audio:  (Griffin-Lim Algorithm)\n","    sample_list = []        #    [sample1, sample2, ....]\n","    for k in tqdm(range(audio_samples.shape[0]), desc=\"current samples:\"):\n","        sample = inverse_op(audio_samples[k])\n","        sample_list.append(sample)\n","    audio_list.append(sample_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8Y6yYxxWZRI","outputId":"642de221-cb19-4b55-ebe9-fac269d925a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(130816,)\n","(130816,)\n","(130816,)\n","(130816,)\n","Gen Success !!\n"]}],"source":["# Save Samples:\n","path_list = []\n","for i in range(sample_num):      # sample_num\n","    current_audio_list = []\n","    for k in range(window_num):\n","        current_audio_list.append(audio_list[k][i])\n","    current_audio = np.concatenate(current_audio_list,0)\n","    print(current_audio.shape)\n","    sf.write(os.path.join(save_path, \"sample_{}_diff.wav\").format(i), current_audio, 16000)\n","    path_list.append(os.path.join(save_path, \"sample_{}_diff.wav\").format(i))\n","print(\"Gen Success !!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ly93Q1QKWZRJ","outputId":"5bf93739-0e02-41a6-f617-107130a1b7e4"},"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Gen Success !!\n"]},{"name":"stderr","output_type":"stream","text":[]}],"source":["# Concat The Video and Sound:\n","import subprocess\n","src_video_path = new_video_path\n","for i in range(sample_num):\n","    gen_audio_path = path_list[i]\n","    out_path = os.path.join(save_path, \"output_{}.mp4\".format(i))\n","    cmd = [\"ffmpeg\" ,\"-i\" ,src_video_path,\"-i\" , gen_audio_path ,\"-c:v\" ,\"copy\" ,\"-c:a\" ,\"aac\" ,\"-strict\" ,\"experimental\", out_path]\n","    # cmd = [\"ffmpeg\" ,\"-i\" ,src_video_path,\"-i\" , gen_audio_path ,\"-c:v\" ,\"copy\" ,\"-c:a\" ,\"mp3\" ,\"-strict\" ,\"experimental\", out_path]\n","    subprocess.check_call(cmd)\n","print(\"Gen Success !!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lvQw3l6WZRJ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"specvqgan","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}